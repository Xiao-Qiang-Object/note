#!/bin/bash

# start_time: 2019-04-11
# end_time: 9999-12-31
# frequency:  day
# author: 
# description: hive数据监控
# create_time:
# change:

#打印日志
print_log()
{
    current_time=$(date "+%Y-%m-%d %H:%M:%S")
    echo "$current_time $@"
}

startsec=$(date +%s)
source /data/etlscript/PUBLIC/SCRIPT/TOOL/scriptHelper.sh
resoveJson $1
## 检查日志路径.
checkLogPath $task_name
exec &> $CMRH_DATAHUB_SCRIPT_LOG/$EXE_DATE/$task_name/$run_serial_no.log

##参数名定义
job_path=$0

sh_directory=`echo ${job_path%/*}`
#脚本名称
job_name=`echo ${job_path##*/}`
job_name=`echo ${job_name%.*}`
hivejdbc="jdbc:hive2://${src_ip}:${src_port}"
mysqljdbc="jdbc:mysql://$dest_ip:$dest_port/$dest_dbname?useUnicode=true&characterEncoding=utf-8"
sh_directory=`echo ${job_path%/*}`

print_log "job_path:$job_path"
print_log "sh_directory:$sh_directory"
print_log "job_name:$job_name"

pdate=${inc_start:0:8}
begin_date=${pdate:0:4}"-"${pdate:4:2}"-"${pdate:6:2}

beeline -u $hivejdbc -n $src_user -p $src_password -e "
use cmf_cmcs;
SET mapred.job.queue.name=${hive_queue};
SET mapred.job.name=${job_name};

drop table if exists cmwt_t_hive_exception_notice_tmp;

create table if not exists cmwt_t_hive_exception_notice_tmp(
 notice_id                string           comment '自增ID'
,notice_type              string           comment '预警类型'
,notice_member            string           comment '预警通知成员企业（如：cmrh、cmbs、cmzq）'
,notice_name              string           comment '预警通知名称（此次预警任务的名称）'
,notice_comment           string           comment '预警通知备注（对此次预警任务的描述）'
,notice_sql               string           comment '预警通知依据的sql'
,notice_datasource        string           comment '预警通知涉及的数据源'
,notice_users             string           comment '预警通知涉及的用户列表'
,created_time             string           comment '此次预警通知定时任务创建时间'
,notice_switch            string           comment '此次预警通知任务线程对应的开关状态(1表示开；0表示关)'
,notice_flag              string           comment '预警频度类型（周期性、持续性）'
,cron_schedule            string           comment '任务的定时时间'
,execute_flag             string           comment '发送信息的方式（1：微信，2：邮件不带附件，3：邮件带附件）'
,updated_time             string           comment '预警任务执行时的时间，在一次性任务里用来标识当天执行还是其他天执行'
)
comment 'KPI指标结果'
row format delimited  fields terminated by '\001' stored as textfile;

";

# 检查执行状况
exitCodeCheck $? $startsec $run_serial_no $task_name

sqoop import \
--connect $mysqljdbc \
--username $dest_user \
--password $dest_password \
--table t_exception_notice \
--null-string '' \
--null-non-string '\\N' \
--fields-terminated-by '\001' -m 2 \
--delete-target-dir \
--hive-import \
--hive-overwrite \
--hive-database cmf_cmcs \
--hive-table cmwt_t_hive_exception_notice_tmp

# 检查执行状况
exitCodeCheck $? $startsec $run_serial_no $task_name

notice_id_file=${sh_directory}/notice_id_file.csv
sql_file=${sh_directory}/sql_file.csv
sql_line=${sh_directory}/sql_line.csv
sql_result=${sh_directory}/sql_result.csv
hive_result=${sh_directory}/hive_result.csv


if [ -f $sql_file ];then
    rm $sql_file
fi

if [ -f $sql_result ];then
    rm $sql_result
fi

if [ -f $sql_line ];then
    rm $sql_line
fi

if [ -f $hive_result ];then
    rm $hive_result
fi

hadoop fs -test -e /data/ftpFiles/cmcs/tmp/t_exception_notice
if [ $? -eq 0 ] ;then
  hdfs dfs -rm -r /data/ftpFiles/cmcs/tmp/t_exception_notice
else
  echo 'HDFS目录已删除'
fi


beeline -u $hivejdbc -n $src_user -p $src_password -e "
use cmf_cmcs;
SET mapred.job.queue.name=${hive_queue};
SET mapred.job.name=${job_name};

select m.notice_sql_oth
  from (select concat(q.rt,q.notice_sql_behind) notice_sql_oth,q.*
          from (select p.*,regexp_replace(p.notice_sql_front,'from',p.concat_field) rt
                  from (select k.*,substr(k.notice_sql,1,notice_sql_pos + 3) notice_sql_front
                              ,substr(k.notice_sql,notice_sql_pos + 4) notice_sql_behind
                              ,concat(',',k.notice_id,' notice_id',' from ') concat_field
                         from (select  LOCATE('from',lower(t.notice_sql)) notice_sql_pos
                                      ,t.*
                                 from cmwt_t_hive_exception_notice_tmp t
                                where t.notice_datasource = 'hive'
                                  and t.notice_switch = 1) k) p) q) m;

" > ${sql_file}

sed -i '1,3d' ${sql_file}
sed -i '$d' ${sql_file}
sed -i "s/|//g" ${sql_file}

cat ${sql_file} | while read line
do
  beeline -u $hivejdbc -n $src_user -p $src_password --outputformat=csv2 -e "$line" > ${sql_result}
  sed -n '2,$p' ${sql_result} >> ${sql_line}
done

##在hdfs上创建临时目录存放结果文件
hadoop fs -test -e /data/ftpFiles/cmcs/tmp/t_exception_notice
if [ $? -eq 0 ] ;then
  echo '目录已存在'
else
  hdfs dfs -mkdir /data/ftpFiles/cmcs/tmp/t_exception_notice
fi

##将数据文件上传到hdfs上
hdfs dfs -put ${sql_line} /data/ftpFiles/cmcs/tmp/t_exception_notice

##授权
hadoop fs -chmod -R 777 /data/ftpFiles/cmcs/tmp/

beeline -u $hivejdbc -n $src_user -p $src_password -e "
use cmf_cmcs;

SET mapred.job.queue.name=${hive_queue};
SET mapred.job.name=${job_name};

drop table if exists ads_cmwt_data_insight_report_tmp;

create table if not exists ads_cmwt_data_insight_report_tmp
( mem_id               string         comment'成员企业id'
 ,category_code        string         comment'统计分类'
 ,stat_date            string         comment'统计时间'
 ,key                  string         comment'键'
 ,value                string         comment'值'
 ,create_time          string         comment'创建时间'
 ,notice_id            string         comment'唯一标识'
)
comment'KPI指标结果'
ROW FORMAT DELIMITED  FIELDS TERMINATED BY ',' STORED AS TEXTFILE;

load data inpath 'hdfs:/data/ftpFiles/cmcs/tmp/t_exception_notice/*' into table ads_cmwt_data_insight_report_tmp;

"
exitCodeCheck $? $startsec $run_serial_no $task_name

sqoop export \-D mapred.job.queue.name=${job_name} \
--connect $mysqljdbc \
--username $dest_user \
--password $dest_password \
--update-key "mem_id,category_code,stat_date,key" \
--update-mode allowinsert \
--table t_cmwt_data_insight_report -m 1 \
--export-dir /user/hive/warehouse/cmf_cmcs.db/ads_cmwt_data_insight_report_tmp \
--columns mem_id,category_code,stat_date,key,value,create_time,notice_id \
--input-null-string '\\N' \
--input-null-non-string '\\N' \
--input-fields-terminated-by ','

exitCodeCheck $? $startsec $run_serial_no $task_name

beeline -u $hivejdbc -n $src_user -p $src_password -e "
use cmf_cmcs;

SET mapred.job.queue.name=${hive_queue};
SET mapred.job.name=${job_name};

drop table if exists cmwt_t_hive_exception_notice_tmp;
drop table if exists ads_cmwt_data_insight_report_tmp;

"
exitCodeCheck $? $startsec $run_serial_no $task_name

if [ -f $sql_file ];then
    rm $sql_file
fi

if [ -f $sql_result ];then
    rm $sql_result
fi

if [ -f $sql_line ];then
    rm $sql_line
fi

if [ -f $hive_result ];then
    rm $hive_result
fi

hadoop fs -test -e /data/ftpFiles/cmcs/tmp/t_exception_notice
if [ $? -eq 0 ] ;then
  hdfs dfs -rm -r /data/ftpFiles/cmcs/tmp/t_exception_notice
else
  echo 'HDFS目录已删除'
fi

exitCodeCheck $? $startsec $run_serial_no $task_name
### 代码段-结束
## 结束任务 ###################################
endsec=$(date +%s)
message="脚本耗时: $[ endsec-startsec ] 秒"
echo $message

# 回调 调度系统
callDatahub 0 "$message" "$run_serial_no" "$task_name"
